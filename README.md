# Taming-Big-Data-with-Apache-Spark-and-Python---Udemy
Learnt the concepts of Spark's DataFrames and Resilient Distributed Datastores.
Developed and ran Spark jobs quickly using Python and pyspark.
Translated complex analysis problems into iterative or multi-stage Spark scripts.
Scaled up to larger data sets using Amazon's Elastic MapReduce service.
Understood how Hadoop YARN distributes Spark across computing clusters.
Learnt about other Spark technologies, like Spark SQL, Spark Streaming, and GraphX.
